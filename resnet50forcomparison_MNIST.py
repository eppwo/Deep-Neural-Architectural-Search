# -*- coding: utf-8 -*-
"""ResNet152ForComparison

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XmBhS-eZt4DZx6c-RnbPzxMopM6nsib1
"""

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
"""
Created on Sat Nov 13 17:05:28 2021

@authors: Emilie P. P. W. Olesen - s164060 & Rebekka D. Beneke - s153805

Based on https://www.youtube.com/watch?v=DkNIBBBvcPs and https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py
"""

# Install tensorboard for data visualization
#!pip install tensorboard


# Environmental variable
CUDA_LAUNCH_BLOCKING=1

# Import packages 
import sys
#import tensorflow as tf
import datetime, os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader, random_split, Subset
from torch.nn.parameter import Parameter
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
from torchvision import transforms
from tqdm.autonotebook import tqdm
from sklearn.metrics import classification_report
import time
import matplotlib.pyplot as plt
from tqdm import tqdm
import numpy as np
from torch.distributions import Categorical, Normal
#import torch.utils.tensorboard as tb
torch.set_printoptions(linewidth=120)
#from torch.utils import tensorboard
#from torch.utils.tensorboard import SummaryWriter
#from tensorboard import notebook
# %pylab inline
# %load_ext tensorboard


import tempfile

# Settings and data
# Device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


# Hyperparameters
random_seed = 123
learning_rate = 3e-4 #0.01
num_epochs = 20
batch_size = 128
num_epochs_NAS = 10 # This is the number of epochs we wish to update our network variables in the NAS.

# Architecture
num_classes = 10
img_channels = 1

class block(nn.Module):
    def __init__(self, in_channels, out_cannels, identity_downsample = None, stride = 1):
        super(block, self).__init__()
        self.explansion = 4 
        self.conv1 = nn.Conv2d(in_channels, out_cannels, kernel_size = 1, stride = 1, padding = 0)
        self.bn1 = nn.BatchNorm2d(out_cannels)
        self.conv2 = nn.Conv2d(out_cannels, out_cannels, kernel_size = 3, stride = stride, padding = 1)
        self.bn2 = nn.BatchNorm2d(out_cannels)
        self.conv3 = nn.Conv2d(out_cannels, out_cannels*self.explansion, kernel_size = 1, stride = 1, padding = 0)
        self.bn3 = nn.BatchNorm2d(out_cannels*self.explansion)
        self.relu = nn.ReLU()
        self.identity_downsample = identity_downsample
        
    def forward(self, x):
        identity = x
        
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.bn3(x)
        
        if self.identity_downsample is not None:
            identity = self.identity_downsample(identity)
            
        x += identity
        x = self.relu(x)
        return x
    
class ResNet(nn.Module):  # [3, 4, 6, 3]
    def __init__(self, block, layers, image_channels, num_classes):
        super(ResNet, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size = 7, stride = 2, padding = 3)
        # Nedenstående kan implementeres, hvis vi vil teste udfaldet af forskellige conv lag. Valget af conv lag skal så afhænge af størrelsen på input som skal tilføjes ovenfor i initialiseringen kernel_size 
        #if kernel_size = 3
          #self.conv1 = nn.Conv2d(image_channels, 64, kernel_size = 7, stride = 2, padding = 3)
        #if kernel_size = 5
          #self.conv1 = nn.Conv2d(image_channels, 64, kernel_size = 7, stride = 2, padding = 3)
        #if kernel_size = 7
          #self.conv1 = nn.Conv2d(image_channels, 64, kernel_size = 7, stride = 2, padding = 3)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)
        
        # ResNet layers
        self.layer1 = self._make_layer(block, layers[0], out_channels = 64, stride = 1)
        self.layer2 = self._make_layer(block, layers[1], out_channels = 128, stride = 2)
        self.layer3 = self._make_layer(block, layers[2], out_channels = 256, stride = 2)        
        self.layer4 = self._make_layer(block, layers[3], out_channels = 512, stride = 2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1,1))
        self.fc = nn.Linear(512*4, num_classes)
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
  

        x = self.layer1(x)
        x = self.layer2(x)        
        x = self.layer3(x)
        x = self.layer4(x)
        
        x = self.avgpool(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc(x)
        return x

            
            
    def _make_layer(self, block, num_residual_blocks, out_channels, stride):
        identity_downsample = None
        layers = []
        
        if stride != 1 or self.in_channels != out_channels * 4:
            identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size = 1, stride = stride,), nn.BatchNorm2d(out_channels*4))
        
        
        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))
        self.in_channels = out_channels * 4
        

        for i in range(num_residual_blocks - 1):
            layers.append(block(self.in_channels, out_channels))
            
            return nn.Sequential(*layers)


def ResNet18(img_channels, num_classes):
    return ResNet(block, [2, 2, 2, 2], img_channels, num_classes)


def ResNet50(img_channels, num_classes): 
    return ResNet(block, [3, 4, 6, 3], img_channels, num_classes)

def ResNet101(img_channels, num_classes):
    return ResNet(block, [3, 4, 23, 3], img_channels, num_classes)        

def ResNet152(img_channels, num_classes):
    return ResNet(block, [3, 4, 36, 3], img_channels, num_classes)

# Load MNIST data:
train_ds = MNIST("mnist", train=True, download=True, transform=ToTensor())
test_ds = MNIST("mnist", train=False, download=True, transform=ToTensor())

# x_train = train_ds_mainset.data[:1000].view(-1, 784).float()
# # # Build data loader
train_dl = DataLoader(train_ds, batch_size=64, shuffle=True,drop_last=True)
test_dl = DataLoader(test_ds, batch_size=64,drop_last=True)

## Picking out subsets to speed up training
# train_ds = Subset(train_ds, range(0,2000))
# train_dl = DataLoader(train_ds, batch_size=64, shuffle=True, drop_last=True)

# test_ds = Subset(test_ds, range(0,1000))
# test_dl = DataLoader(test_ds, batch_size=64, drop_last=True)

# Monitoring training time of the net


# Attempt from https://github.com/rasbt/stat453-deep-learning-ss21/blob/main/L14/2-resnet-example.ipynb

torch.manual_seed(random_seed)
#optimizer = torch.optim.Adam(NAS_model.parameters(), lr=learning_rate)

def compute_accuracy(NAS_model, data_loader):
  correct_pred, num_examples = 0, 0
  for i, (features, targets) in enumerate(data_loader):            
      features = features.to(device)
      targets = targets.to(device)
      logits = NAS_model(features)
      _, predicted_labels = torch.max(logits, 1)
      num_examples += targets.size(0)
      correct_pred += (predicted_labels == targets).sum()
  return correct_pred.float()/num_examples * 100

# Commented out IPython magic to ensure Python compatibility.
## Def for traning model:

def trainmodel(NAS_model, optimizer):
  start_time = time.time()
  training_accuracy_array = []
  test_accuracy_array = []
  train_loss = []
  test_loss = []  

  #  # Save information from sampled architectures; by initializing empty dictionary
  # architecture = {'Train loss': [], 'Test loss': [], 'Training accuracy': [], 'Test accuracy': []}

  for epoch in range(num_epochs):
      NAS_model = NAS_model.train()


      #logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
     # tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

      #print("Entering training mode")
      for batch_idx, (features, targets) in enumerate(train_dl):
        features = features.to(device)
        targets = targets.to(device)
        
        ### FORWARD AND BACK PROP for training
        logits = NAS_model(features)
        cost = torch.nn.functional.cross_entropy(logits, targets)
        train_loss.append(cost)
        optimizer.zero_grad()
        cost.backward()
        
        ### UPDATE MODEL PARAMETERS
        optimizer.step()
            
      # ### LOGGING
      if epoch % 1 == 0:
            # print ('Epoch: %03d/%03d | Train cost: %.4f' 
            #       %(epoch+1, num_epochs, cost))
            print ('Epoch: %03d/%03d' 
                   %(epoch+1, num_epochs))

        # Leave training enter evaluation mode

      #print("Entering evaluation mode")
      NAS_model =NAS_model.eval() # eval mode to prevent upd. batchnorm params during inference

      for batch_idx, (features, targets) in enumerate(test_dl):
      
        features = features.to(device)
        targets = targets.to(device)
        
        ### FORWARD AND BACK PROP for training
        logits = NAS_model(features)
        test_cost = torch.nn.functional.cross_entropy(logits, targets)
        test_loss.append(test_cost)
        optimizer.zero_grad()
        
        test_cost.backward()
        
        ### UPDATE MODEL PARAMETERS
        optimizer.step()
        
  #       ### LOGGING
      if epoch % 1 == 0:
        # print ('Epoch: %03d/%03d | Test cost: %.4f' 
        #         %(epoch+1, num_epochs, test_cost))
        print ('Epoch: %03d/%03d' 
                 %(epoch+1, num_epochs))

        with torch.set_grad_enabled(False): # save memory during inference
          # Compute accuracy
          training_accuracy = compute_accuracy(NAS_model, train_dl)
          test_accuracy = compute_accuracy(NAS_model, test_dl)
          train_loss.append(cost)
          test_loss.append(test_cost)
          print('Epoch: %03d/%03d training accuracy: %.2f%%' % (epoch+1, num_epochs, compute_accuracy(NAS_model, train_dl)))
          print('Epoch: %03d/%03d test accuracy: %.2f%%' % (epoch+1, num_epochs, compute_accuracy(NAS_model, test_dl)))
          #append the accuracy for each epoch
          training_accuracy_array.append(training_accuracy)
          test_accuracy_array.append(test_accuracy)

      # architecture['Train loss'].append(cost)
      # architecture['Test loss'].append(test_cost)
      # architecture['Training accuracy'].append(training_accuracy)
      # architecture['Test accuracy'].append(test_accuracy)

      # print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))
      
  # plt.figure()
  # plt.plot(training_accuracy_array, '-.r',linewidth= 3)
  # plt.plot(test_accuracy_array, 'ob', linewidth = 1)
  # plt.legend(['Training accuracy', 'Test accuracy'])
  # plt.xlabel('Epochs')
  # plt.ylabel('Accuracy')
  # plt.show()
  return cost, test_cost, training_accuracy, test_accuracy, train_loss, test_loss, training_accuracy_array, test_accuracy_array

# Monitoring training time of the net



# Attempt from https://github.com/rasbt/stat453-deep-learning-ss21/blob/main/L14/2-resnet-example.ipynb

torch.manual_seed(random_seed)
model = ResNet50(img_channels, num_classes)
model = model.to(device)
#model = model.to("cuda")

loss_fn=nn.CrossEntropyLoss()    
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

trainedmodel = trainmodel(model, optimizer)